{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yelp_reviews-using-stars-lstm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dCpZvAvIaBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9h5A6SxK8Y0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b4241d0f-3687-40bb-a2d2-90d093e40014"
      },
      "source": [
        "df = pd.read_csv(\"on_resto_chinese_tokens.csv\", engine=\"python\")\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>business_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>state</th>\n",
              "      <th>rating</th>\n",
              "      <th>categories</th>\n",
              "      <th>star_categories</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>jlu4CztcSxrKx56ba1a5AQ</td>\n",
              "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
              "      <td>ON</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Food, Chinese, Restaurants, Desserts</td>\n",
              "      <td>Bad</td>\n",
              "      <td>['tracy', 'dessert', 'big', 'hong', 'kong', 'm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nkSf1NKWFGiAyrnCa-A5UA</td>\n",
              "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
              "      <td>3.0</td>\n",
              "      <td>The squid balls were AMAZING. Crispy exterior ...</td>\n",
              "      <td>ON</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Food, Chinese, Restaurants, Desserts</td>\n",
              "      <td>Bad</td>\n",
              "      <td>['squid', 'ball', 'amazing', 'crispy', 'exteri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>jG7130OQWiftvHhtyabsog</td>\n",
              "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
              "      <td>4.0</td>\n",
              "      <td>Must Try: Mango Sago with Pommels, Shaved Ice ...</td>\n",
              "      <td>ON</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Food, Chinese, Restaurants, Desserts</td>\n",
              "      <td>Good</td>\n",
              "      <td>['try', 'mango', 'sago', 'pommel', 'shave', 'i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wdCwBv_TA_Y-IjUZv2HWWQ</td>\n",
              "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
              "      <td>1.0</td>\n",
              "      <td>We came on a Friday and the store said that th...</td>\n",
              "      <td>ON</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Food, Chinese, Restaurants, Desserts</td>\n",
              "      <td>Bad</td>\n",
              "      <td>['come', 'friday', 'store', 'say', 'open', 'pm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>kxz6Q2AERQeo9x6nnbHZNg</td>\n",
              "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
              "      <td>3.0</td>\n",
              "      <td>I think this is a cool little hang out place f...</td>\n",
              "      <td>ON</td>\n",
              "      <td>3.5</td>\n",
              "      <td>Food, Chinese, Restaurants, Desserts</td>\n",
              "      <td>Bad</td>\n",
              "      <td>['think', 'cool', 'little', 'hang', 'place', '...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  user_id  ...                                             tokens\n",
              "0  jlu4CztcSxrKx56ba1a5AQ  ...  ['tracy', 'dessert', 'big', 'hong', 'kong', 'm...\n",
              "1  nkSf1NKWFGiAyrnCa-A5UA  ...  ['squid', 'ball', 'amazing', 'crispy', 'exteri...\n",
              "2  jG7130OQWiftvHhtyabsog  ...  ['try', 'mango', 'sago', 'pommel', 'shave', 'i...\n",
              "3  wdCwBv_TA_Y-IjUZv2HWWQ  ...  ['come', 'friday', 'store', 'say', 'open', 'pm...\n",
              "4  kxz6Q2AERQeo9x6nnbHZNg  ...  ['think', 'cool', 'little', 'hang', 'place', '...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QvQtBFVbHh7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_len = [len(token_list) for token_list in df['tokens']]"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuThb-nfbR3K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26135124-36e8-4b12-884e-7e193087ac88"
      },
      "source": [
        "from scipy import stats\n",
        "stats.describe(np.array(token_len))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DescribeResult(nobs=51621, minmax=(2, 5607), mean=528.6434396853994, variance=191404.27758912923, skewness=2.1994617994550083, kurtosis=8.050708549409517)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAY_4syicBdA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "946da36b-afb5-49ef-e917-90b8d3341376"
      },
      "source": [
        "import math\n",
        "#Get the 75th percentile\n",
        "528 + (0.674)*(191404)**(0.5)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "822.8732668520495"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HGQt8LdLBlS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "24687f75-8340-475e-9744-21a446deeb82"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "\n",
        "# Build LSTM\n",
        "max_words = 20000\n",
        "maxlen=823\n",
        "batch_size = 32\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words, 64, input_length=maxlen))\n",
        "model.add(LSTM(64, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_4 (Embedding)      (None, 823, 64)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm_4 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,313,089\n",
            "Trainable params: 1,313,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6K4w_ZlMTDh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Split Test/Train\n",
        "from sklearn.model_selection import train_test_split \n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words = max_words)\n",
        "tokenizer.fit_on_texts(df['tokens'])\n",
        "\n",
        "df['tokens']= df['tokens'].astype(str)\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.33, random_state=42)\n",
        "\n",
        "feature = 'tokens'\n",
        "target = 'star_categories'\n",
        "\n",
        "#Train\n",
        "X_train = train[feature]\n",
        "#Convert X_train to sequence\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "#Pad sequence to max_len\n",
        "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
        "#Convert Good/Bad to 1/0 and to array\n",
        "y_train = np.array([ 1 if target =='Good' else 0 for target in train[target]])\n",
        "\n",
        "# Validation Sets\n",
        "X_test = test[feature]\n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
        "y_test = np.array([ 1 if target =='Good' else 0 for target in test[target]])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqQTPIjiNm44",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "afed139e-6b19-4410-fd8a-28b715c48855"
      },
      "source": [
        "unicorns = model.fit(X_train, y_train,\n",
        "          batch_size=batch_size, \n",
        "          epochs=5, \n",
        "          validation_data=(X_test,y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1081/1081 [==============================] - 1202s 1s/step - loss: 0.4597 - acc: 0.7897 - val_loss: 0.4006 - val_acc: 0.8190\n",
            "Epoch 2/5\n",
            "1081/1081 [==============================] - 1212s 1s/step - loss: 0.3798 - acc: 0.8321 - val_loss: 0.4027 - val_acc: 0.8181\n",
            "Epoch 3/5\n",
            "1081/1081 [==============================] - 1220s 1s/step - loss: 0.3581 - acc: 0.8437 - val_loss: 0.3925 - val_acc: 0.8237\n",
            "Epoch 4/5\n",
            "1062/1081 [============================>.] - ETA: 21s - loss: 0.3379 - acc: 0.8539"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_lAvz0dOjhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns.history['acc'])\n",
        "plt.plot(unicorns.history['val_acc'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW2Ml_0NauTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}